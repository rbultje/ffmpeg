vp9:
- try to replace the ugly ref frame context (for bitstream parsing) with
  some kind of LUT
- prefetch magic
- remove all memsets in context setting (above/left) and replace with faster
  versions that understand we're only ever writing 1,2,4,8,16 bytes.
- likewise, use faster variants in intra pred preparation code
- split coefficient reading in 2 functions, one for 32x32, one for rest
- coefficient parsing dc contextualization using surrounding eob>0 is slow
  and can be done in a single step
- fix overhangs (e.g. if a block is 32pixels out of visible frame area, and
  we're not using edges in allocation, then we overwrite the start of the
  next line); write a fate test to regtest this (e.g. 65x65 image with using
  64x32 for bottomleft sb64 and 32x64 for topright sb64; use the tx32x32 to
  trigger this in itxfm_add as well as prediction.
- replace loopfilter masking logic with uint64_t LUTs
- maybe add itxfm_add_blk variants for inter (to do multiple 4x4 per time)
- x86 simd
- frame/tile mt
- scalable/resolution changing
- fate tests for resolution changing, tiling (row/col), segmentation
- put boolcoder on stack of coeff decoder or mode decoder (see vp8/h264)

